{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shayok/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/shayok/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/shayok/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/shayok/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import scipy.signal as signal #signal processing stuff (e.g. filters, hilbert transform, etc.)\n",
    "from scipy.stats import linregress\n",
    "import scipy\n",
    "import struct\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "import svgutils.transform as sg\n",
    "import sys\n",
    "\n",
    "#nelpy!\n",
    "import nelpy as nel  #recommended import for nelpy\n",
    "import nelpy.plotting as npl  #recommended import for the nelpy plotting library\n",
    "import nelpy.io.trodes as neltro\n",
    "\n",
    "#I saved my online ripple detection filter taps and stuff in a file....gonna import this for all analysis\n",
    "import imp\n",
    "ripple_filtering = imp.load_source('ripple_filtering', '/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/DataAnalysisScripts/ripple_filtering.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#paper plot settings\n",
    "sns.set(rc={'figure.figsize': (12, 4),'lines.linewidth': 1, 'font.size': 18, 'axes.labelsize': 16, 'axes.titlesize':18, 'legend.fontsize': 12, 'ytick.labelsize': 12, 'xtick.labelsize': 12 })\n",
    "sns.set_style('white')\n",
    "sns.set_color_codes(palette='colorblind')\n",
    "#plots show up within jupyter for matplotlib\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FS=3000\n",
    "FS_system=30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Loading LFP Timestamps*****************\n",
      "b'<Start settings>\\n'\n",
      "b'Description: LFP timestamps\\n'\n",
      "b'Byte_order: little endian\\n'\n",
      "b'Original_file: singleChan.rec\\n'\n",
      "b'Clock rate: 30000\\n'\n",
      "b'Decimation: 1\\n'\n",
      "b'Time_offset: 0\\n'\n",
      "b'Fields: <time uint32>\\n'\n",
      "Current file position 185\n",
      "Done!\n",
      "*****************Loading LFP Data*****************\n",
      "b'<Start settings>\\n'\n",
      "b'Description: LFP data for one channel\\n'\n",
      "b'Byte_order: little endian\\n'\n",
      "b'Original_file: singleChan.rec\\n'\n",
      "b'nTrode_ID: 2\\n'\n",
      "b'nTrode_channel: 1\\n'\n",
      "b'Clock rate: 30000\\n'\n",
      "b'Voltage_scaling: 0.195\\n'\n",
      "b'Decimation: 1\\n'\n",
      "b'First_timestamp: 19935\\n'\n",
      "b'Reference: on\\n'\n",
      "b'Low_pass_filter: 400\\n'\n",
      "b'Fields: <voltage int16>\\n'\n",
      "Current file position 294\n",
      "*****************Loading LFP Data*****************\n",
      "b'<Start settings>\\n'\n",
      "b'Description: LFP data for one channel\\n'\n",
      "b'Byte_order: little endian\\n'\n",
      "b'Original_file: singleChan.rec\\n'\n",
      "b'nTrode_ID: 3\\n'\n",
      "b'nTrode_channel: 1\\n'\n",
      "b'Clock rate: 30000\\n'\n",
      "b'Voltage_scaling: 0.195\\n'\n",
      "b'Decimation: 1\\n'\n",
      "b'First_timestamp: 19935\\n'\n",
      "b'Reference: on\\n'\n",
      "b'Low_pass_filter: 400\\n'\n",
      "b'Fields: <voltage int16>\\n'\n",
      "Current file position 294\n",
      "*****************Loading LFP Data*****************\n",
      "b'<Start settings>\\n'\n",
      "b'Description: LFP data for one channel\\n'\n",
      "b'Byte_order: little endian\\n'\n",
      "b'Original_file: singleChan.rec\\n'\n",
      "b'nTrode_ID: 4\\n'\n",
      "b'nTrode_channel: 1\\n'\n",
      "b'Clock rate: 30000\\n'\n",
      "b'Voltage_scaling: 0.195\\n'\n",
      "b'Decimation: 1\\n'\n",
      "b'First_timestamp: 19935\\n'\n",
      "b'Reference: on\\n'\n",
      "b'Low_pass_filter: 400\\n'\n",
      "b'Fields: <voltage int16>\\n'\n",
      "Current file position 294\n",
      "19940\n",
      "Data decimated to match data sent to modules\n"
     ]
    }
   ],
   "source": [
    "filePath = \"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/singleChan.LFP/singleChan.timestamps.dat\"\n",
    "print(\"*****************Loading LFP Timestamps*****************\")\n",
    "f = open(filePath,'rb')\n",
    "instr = f.readline()\n",
    "while (instr != b'<End settings>\\n') :\n",
    "   print(instr)\n",
    "   instr = f.readline()\n",
    "print('Current file position', f.tell())\n",
    "timeStamps = np.fromfile(f, dtype=np.uint32)\n",
    "timeStampsSeconds = (timeStamps-timeStamps[0])/FS_system\n",
    "print(\"Done!\")\n",
    "\n",
    "filePath = \"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/singleChan.LFP/singleChan.LFP_nt2ch1.dat\" \n",
    "print(\"*****************Loading LFP Data*****************\")\n",
    "f = open(filePath,'rb')\n",
    "instr = f.readline()\n",
    "while (instr != b'<End settings>\\n') :\n",
    "   print(instr)\n",
    "   instr = f.readline()\n",
    "print('Current file position', f.tell())\n",
    "dataT2 = np.fromfile(f, dtype=np.int16)\n",
    "\n",
    "filePath = \"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/singleChan.LFP/singleChan.LFP_nt3ch1.dat\"\n",
    "print(\"*****************Loading LFP Data*****************\")\n",
    "f = open(filePath,'rb')\n",
    "instr = f.readline()\n",
    "while (instr != b'<End settings>\\n') :\n",
    "   print(instr)\n",
    "   instr = f.readline()\n",
    "print('Current file position', f.tell())\n",
    "dataT3 = np.fromfile(f, dtype=np.int16)\n",
    "\n",
    "filePath = \"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/singleChan.LFP/singleChan.LFP_nt4ch1.dat\"\n",
    "print(\"*****************Loading LFP Data*****************\")\n",
    "f = open(filePath,'rb')\n",
    "instr = f.readline()\n",
    "while (instr != b'<End settings>\\n') :\n",
    "   print(instr)\n",
    "   instr = f.readline()\n",
    "print('Current file position', f.tell())\n",
    "dataT4 = np.fromfile(f, dtype=np.int16)\n",
    "\n",
    "#Decimate\n",
    "start = 0\n",
    "while(timeStamps[start]%10 != 0):\n",
    "    start+=1\n",
    "timeStamps = timeStamps[start::10]\n",
    "dataT2 = dataT2[start::10]\n",
    "dataT3 = dataT3[start::10]\n",
    "dataT4 = dataT4[start::10]\n",
    "timeStampsSeconds = timeStampsSeconds[start::10]\n",
    "print(timeStamps[0])\n",
    "print(\"Data decimated to match data sent to modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shayok/anaconda3/lib/python3.5/site-packages/scipy/signal/signaltools.py:1336: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/home/shayok/anaconda3/lib/python3.5/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/home/shayok/anaconda3/lib/python3.5/site-packages/scipy/signal/signaltools.py:1333: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/home/shayok/anaconda3/lib/python3.5/site-packages/scipy/signal/signaltools.py:1342: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    }
   ],
   "source": [
    "# Only run first time for data generation! This takes a while otherwise\n",
    "smoothed_envelope2, rippleData2 = ripple_filtering.rippleBandFilterSimulated(dataT2, timeStampsSeconds, FS,ripple_filtering.bandpassFilterTaps,ripple_filtering.lowpassFilterTaps)\n",
    "smoothed_envelope3, rippleData3 = ripple_filtering.rippleBandFilterSimulated(dataT3, timeStampsSeconds, FS,ripple_filtering.bandpassFilterTaps,ripple_filtering.lowpassFilterTaps)\n",
    "\n",
    "# smoothed_envelope4, rippleData4 = ripple_filtering.rippleBandFilterSimulated(dataT4, timeStampsSeconds, FS,ripple_filtering.bandpassFilterTaps,ripple_filtering.lowpassFilterTaps)\n",
    "\n",
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/smoothed_envelope_simulatedT3.out\",smoothed_envelope3,fmt='%10.5f')\n",
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/smoothed_envelope_simulatedT2.out\",smoothed_envelope2,fmt='%10.5f')\n",
    "\n",
    "# np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/smoothed_envelope_simulatedT4.out\",smoothed_envelope4,fmt='%10.5f')\n",
    "\n",
    "# smoothed_envelope2 = np.loadtxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/smoothed_envelopeT2.out\")\n",
    "smoothed_envelope2, rippleData2 = ripple_filtering.rippleBandFilter(dataT2, timeStampsSeconds, FS=FS)\n",
    "smoothed_envelope3, rippleData3 = ripple_filtering.rippleBandFilter(dataT3, timeStampsSeconds, FS=FS)\n",
    "\n",
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/smoothed_envelopeT3.out\",smoothed_envelope3,fmt='%10.5f')\n",
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/smoothed_envelopeT3.out\",smoothed_envelope2,fmt='%10.5f')\n",
    "\n",
    "# smoothed_envelope4, rippleData4 = ripple_filtering.rippleBandFilter(dataT4, timeStampsSeconds, FS=FS)\n",
    "# np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/smoothed_envelopeT4.out\",smoothed_envelope4,fmt='%10.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smoothed_envelope3, rippleData3 = ripple_filtering.rippleBandFilterSimulated(dataT3, timeStampsSeconds, FS,ripple_filtering.bandpassFilterTaps,ripple_filtering.lowpassFilterTaps)\n",
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/smoothed_envelope_simulatedT3.out\",smoothed_envelope3,fmt='%10.5f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smoothed_envelope2, rippleData2 = ripple_filtering.rippleBandFilterSimulated(dataT2, timeStampsSeconds, FS,ripple_filtering.bandpassFilterTaps,ripple_filtering.lowpassFilterTaps)\n",
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/smoothed_envelope_simulatedT2.out\",smoothed_envelope2,fmt='%10.5f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez_compressed(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/figureData/Figure6/smoothed_envelopeT2.npz\",smoothed_envelopeT2=smoothed_envelope2)\n",
    "np.savez_compressed(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/figureData/Figure6/smoothed_envelopeT3.npz\",smoothed_envelopeT3=smoothed_envelope3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smoothed_envelopeT2 = np.load(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/figureData/Figure6/smoothed_envelopeT2.npz\")['smoothed_envelopeT2']\n",
    "smoothed_envelopeT3 = np.load(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/figureData/Figure6/smoothed_envelopeT3.npz\")['smoothed_envelopeT3']\n",
    "# smoothed_envelopeT4 = np.load(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/figureData/Figure6/smoothed_envelopeT4.npz\")['smoothed_envelopeT4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set threshold, find threshold crossings, and find ripple bounds\n",
    "SecondaryThresholdSigma = 0\n",
    "thresholdSigma = 5\n",
    "lengthCriteria = 0.015 #15 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tetrode 2\n",
    "thresholdT2 = np.mean(smoothed_envelopeT2) + thresholdSigma*np.std(smoothed_envelopeT2)\n",
    "\n",
    "#rippleEvents contains indices of events in smoothed_envelope that meet threshold\n",
    "rippleEventsT2, _ = ripple_filtering.thresholdCrossings(smoothed_envelopeT2, thresholdT2)\n",
    "#remove events that don't meet length criteria\n",
    "rippleEventsT2 = rippleEventsT2[rippleEventsT2[:,1] - rippleEventsT2[:,0] >= np.round(FS * lengthCriteria),:]\n",
    "\n",
    "#find start and end of putative ripple aka when ripple band signal comes back down to mean\n",
    "secondaryThresholdT2 = np.mean(smoothed_envelopeT2) + SecondaryThresholdSigma*np.std(smoothed_envelopeT2)\n",
    "rippleBoundsT2, broaderMaxesT2 = ripple_filtering.thresholdCrossings(smoothed_envelopeT2, secondaryThresholdT2)\n",
    "\n",
    "#find windows that match and where they match aka where in the larger bound window does the smaller bound fit\n",
    "outerBoundaryIndicesT2 = np.searchsorted(rippleBoundsT2[:,0], rippleEventsT2[:,0])\n",
    "outerBoundaryIndicesT2 = outerBoundaryIndicesT2 - 1 #subtract 1 since searchsorted returns index after where it belongs\n",
    "\n",
    "#Find extended boundaries for ripple events by pairing to largere window\n",
    "#   (Note that there may be repeats if the larger window contains multiple > 3SD sections)\n",
    "rippleBoundsT2 = rippleBoundsT2[outerBoundaryIndicesT2,:]\n",
    "rippleMaxesT2 = broaderMaxesT2[outerBoundaryIndicesT2]\n",
    "\n",
    "# Now, since all that we care about are the larger windows, so we should get rid of repeats\n",
    "_, unique_idxT2 = np.unique(rippleBoundsT2[:,0], return_index=True)\n",
    "rippleBoundsT2 = rippleBoundsT2[unique_idxT2,:]\n",
    "rippleMaxesT2 = rippleMaxesT2[unique_idxT2]\n",
    "rippleEventsT2 = rippleEventsT2[unique_idxT2,:]\n",
    "\n",
    "offlineRippleDetectionsT2 = np.zeros(smoothed_envelopeT2.size)\n",
    "for i in range(0, rippleMaxesT2.size):\n",
    "    offlineRippleDetectionsT2[(rippleBoundsT2[i][0]):(rippleBoundsT2[i][1])] = rippleMaxesT2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tetrode 3\n",
    "thresholdT3 = np.mean(smoothed_envelopeT3) + thresholdSigma*np.std(smoothed_envelopeT3)\n",
    "\n",
    "#rippleEvents contains indices of events in smoothed_envelope that meet threshold\n",
    "rippleEventsT3, _ = ripple_filtering.thresholdCrossings(smoothed_envelopeT3, thresholdT3)\n",
    "#remove events that don't meet length criteria\n",
    "rippleEventsT3 = rippleEventsT3[rippleEventsT3[:,1] - rippleEventsT3[:,0] >= np.round(FS * lengthCriteria),:]\n",
    "\n",
    "#find start and end of putative ripple aka when ripple band signal comes back down to mean\n",
    "secondaryThresholdT3 = np.mean(smoothed_envelopeT3) + SecondaryThresholdSigma*np.std(smoothed_envelopeT3)\n",
    "rippleBoundsT3, broaderMaxesT3 = ripple_filtering.thresholdCrossings(smoothed_envelopeT3, secondaryThresholdT3)\n",
    "\n",
    "#find windows that match and where they match aka where in the larger bound window does the smaller bound fit\n",
    "outerBoundaryIndicesT3 = np.searchsorted(rippleBoundsT3[:,0], rippleEventsT3[:,0])\n",
    "outerBoundaryIndicesT3 = outerBoundaryIndicesT3- 1 #subtract 1 since searchsorted returns index after where it belongs\n",
    "\n",
    "#Find extended boundaries for ripple events by pairing to largere window\n",
    "#   (Note that there may be repeats if the larger window contains multiple > 3SD sections)\n",
    "rippleBoundsT3 = rippleBoundsT3[outerBoundaryIndicesT3,:]\n",
    "rippleMaxesT3 = broaderMaxesT3[outerBoundaryIndicesT3]\n",
    "\n",
    "# Now, since all that we care about are the larger windows, so we should get rid of repeats\n",
    "_, unique_idxT3 = np.unique(rippleBoundsT3[:,0], return_index=True)\n",
    "rippleBoundsT3 = rippleBoundsT3[unique_idxT3,:]\n",
    "rippleMaxesT3 = rippleMaxesT3[unique_idxT3]\n",
    "rippleEventsT3 = rippleEventsT3[unique_idxT3,:]\n",
    "\n",
    "offlineRippleDetectionsT3 = np.zeros(smoothed_envelopeT3.size)\n",
    "for i in range(0, rippleMaxesT3.size):\n",
    "    offlineRippleDetectionsT3[(rippleBoundsT3[i][0]):(rippleBoundsT3[i][1])] = rippleMaxesT3[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_ripple_epochs(epocha, epochb, ):\n",
    "        \"\"\"Finds intersection (overlap) between two sets of epoch arrays.\n",
    "        Sampling rates can be different.\n",
    "\n",
    "        TODO: verify if this requires a merged EpochArray to work properly?\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epoch : nelpy.EpochArray\n",
    "        boundaries : bool\n",
    "            If True, limits start, stop to epoch start and stop.\n",
    "        meta : dict, optional\n",
    "            New dictionary of meta data for epoch ontersection.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        intersect_epochs : nelpy.EpochArray\n",
    "        \"\"\"\n",
    "\n",
    "        new_starts = []\n",
    "        new_stops = []\n",
    "        epoch_a = epocha.copy().merge()\n",
    "        epoch_b = epochb.copy().merge()\n",
    "\n",
    "        for aa in epoch_a.time:\n",
    "            for bb in epoch_b.time:\n",
    "                if (aa[0] <= bb[0] < aa[1]) and (aa[0] < bb[1] <= aa[1]): # b starts after a and is shorter\n",
    "                    new_starts.append(aa[0])\n",
    "                    new_stops.append(aa[1])\n",
    "                elif (aa[0] < bb[0] < aa[1]) and (aa[0] < bb[1] > aa[1]): # b starts after a and is longer\n",
    "                    new_starts.append(aa[0])\n",
    "                    new_stops.append(bb[1])\n",
    "                elif (aa[0] > bb[0] < aa[1]) and (aa[0] < bb[1] < aa[1]): # b starts before a and a is longer\n",
    "                    new_starts.append(bb[0])\n",
    "                    new_stops.append(aa[1])\n",
    "                elif (aa[0] >= bb[0] < aa[1]) and (aa[0] < bb[1] >= aa[1]): # b starts same time or before a and b is longer or same time as a\n",
    "                    new_starts.append(bb[0])\n",
    "                    new_stops.append(bb[1])\n",
    "\n",
    "        epoch_a._time = np.hstack(\n",
    "            [np.array(new_starts)[..., np.newaxis],\n",
    "                np.array(new_stops)[..., np.newaxis]])\n",
    "\n",
    "        return epoch_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<EpochArray at 0x7efc14f71e10: 492 epochs> of duration 3 days 11:21:53 hours"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rippleBounds = merge_ripple_epochs(nel.EpochArray(rippleBoundsT2),nel.EpochArray(rippleBoundsT3))\n",
    "rippleBounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/rippleBoundsStartTwoChan5SD.out\",rippleBounds.starts,fmt='%10.5f')\n",
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/rippleBoundsEndTwoChan5SD.out\",rippleBounds.stops,fmt='%10.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/rippleBoundsStartT25SD.out\",rippleBoundsT2[:,0],fmt='%10.5f')\n",
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/rippleBoundsEndT25SD.out\",rippleBoundsT2[:,1],fmt='%10.5f')\n",
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/rippleBoundsStartT35SD.out\",rippleBoundsT3[:,0],fmt='%10.5f')\n",
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/rippleBoundsEndT35SD.out\",rippleBoundsT3[:,1],fmt='%10.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/rippleBoundsStartTwoChan3SD.out\",rippleBounds[:,0],fmt='%10.5f')\n",
    "np.savetxt(\"/home/shayok/Documents/Code/RippleDetectionAnalysis/Cavaradossi/paperData/twoChanAnalysis/rippleBoundsEndTwoChan3SD.out\",rippleBounds[:,1],fmt='%10.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The comment in cell 20 can easily be implemented in python but I just don't want to think and would rather use a nested loop...so it's gonna be done within the C++ functions voting two channel function! It just makes life easier. I think I have code that does the merging with `nelpy` but this is faster for me to prototype :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call C++ analysis function\n",
    "Compile with below! Note: I just like having all warnings shown really no reason to compile with those flags<br>\n",
    "`g++ -o votingTwoOfThree -Wall -pedantic -std=c++11 -pthread voting2of3.cpp`<br> \n",
    "or <br>\n",
    "`g++ -o votingTwoOfTwo -Wall -pedantic -std=c++11 -pthread voting2of2.cpp` <--- only one used in the paper<br>\n",
    "*make sure single channel is compiled as well with below! Run it only after the two channel begins i*<br>\n",
    "`g++ -o twoChanDefnSingleChanAnalysis -Wall -pedantic -std=c++11 -pthread singleChanAnalysis_twoChanDefn.cpp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "The code here is changed to compile metrics for each one of these. File names have been changed for convenience...compile appropriate .cpp file. The file structure will need to be changed if anyone other than me is running this code\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
